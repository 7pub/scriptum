## Lazy Evaluation on Demand

Lazy evaluation means that expressions are evaluated

* only when needed
* just enough
* only once

The next sections will discuss each point in detail.

#### Normal order evaluation

Applicative order is the common evaluation strategy of imperative and multi-paradigm languages. It evaluates all subexpressions passed to a function as its arguments right before the function is called.

Normal order evaluation passes argument subexpressions to functions as they are and proceeds with their evaluation only if the results are actually needed within the function body:

```javascript
// hypothetical normal evaluation order in Javascript

const add = x => y => x + y;

const foo = add(2 + 3) (4 * 5); // A
//              ^^^^^   ^^^^^ subexpressions
const main = foo + 0; // B
```
With normal evaluation order both subexpressions are not evaluated but passed to `add` as is (line `A`). However, in line `B` the evaluation is forced, because the result of the addition is needed. Let us further look into the evaluation process:

```javascript
foo + 0

// first add's body is inlined with the unevaluated arguments

((2 + 3) + (4 * 5)) + 0

// then the resulting expression is further reduced to normal form

(5 + 20) + 0
25 + 0
25 // normal form
```
#### Weak Head Normal Form (WHNF)

Lazy evaluation also means to evaluate subexpressions just enough, that is to pause evaluation as early as possible. An expression need not to be further reduced when the outermost level is a lambda abstraction. Such an expression is in WHNF, that is it may contain unevaluated subexpressions referred to as thunks. Taking the above example the add function call is in WHNF:

```javascript
// hypothetical WHNF in Javascript

// WHNF

add(2 + 3) (4 * 5)
add(2 + 3)

// not in WHNF

add(2 + 3) (4 * 5) + 1
```
The expression in the last line is not in WHNF, because the outermost level is not a lambda abstraction but the `+` operator with two operands. Hence the expressions require further reduction. Since the `+` operator eagerly requires both operands to be fully evaluated the preceding `add` function call is forced to normal form.

#### Sharing

Lazy evaluation would be very inefficient if it had to evaluate the same subexpression each time it occurs in a function body. For that reason the result of once evaluated subexpressions is stored and shared within the same scope:

```javascript
const foo = x => [
  x + x,
  x - x,
  x * x];

foo(2 + 3);
```
The invocation of `foo` triggers the evaluation of `2 + 3` only once, even though it is used six times.

### Lambda abstractions

As we have seen lazyness defers the evaluation of subexpressions. When we squint hard enough this also applies to ordinary functions, because they are only evaluated when the required arguments are provided. This inherently lazy behavior allows us to partially apply them:

```javascript
const add = x => y => x + y,
  add2 = add(2);
```
#### Eta abstractions

`f` and `x => f(x)` are not the same when it comes to evaluation in an eagerly evaluated language like Javascript. The latter renders a function slightly lazier:

```javascript
const foldMap = f => acc => ix => {
  for (let [i, x] of ix)
    acc = f(acc) (x);

  return acc;
};

const arrSnoc = xs => x =>
  xs.concat([x]);

const mapToArr =
  foldMap(arrSnoc) ([]);

const mapToArr_ = ix =>
//                ^^
  foldMap(arrSnoc) ([]) (ix);
//                      ^^^^

const foo = new Map([[0, "foo"], [1, "bar"], [2, "baz"]]);

mapToArr(foo);
mapToArr_(foo);

mapToArr(foo); // ["foo", "bar", "baz", "foo", "bar", "baz"]
mapToArr_(foo); // ["foo", "bar", "baz"]
```
[run code](https://repl.it/@scriptum/MeanNoxiousChord)

`mapToArr` gets a fresh array as accumulator each time it is called and hence keeps the side effect caused by `arrSnoc` local. Adding redundant lambda abstractions to a derived function is called eta abstraction and the opposite operation eta reduction.

#### Function composition

You can think of function composition as the introduction rule of the function type. If you compose two existing functions you create a new one. Since functions are inherently lazy you can dynamically create new lazy types exhibiting new lazy behavior:

```javascript
const comp = f => g => x => f(g(x));
const flip = f => y => x => f(x) (y);

const inc = x => x + 1;
const strRepeat = n => s => s.repeat(n);

const main = comp(
  flip(strRepeat) ("Hi"))
    (inc);

// nothing evaluated yet

main(2); // "HiHiHi"
```
[run code](https://repl.it/@scriptum/WebbedDryDiskdrive)

#### Continuation passing style

Can we defer the function application even further?

```javascript
const compk = f => g => x => k =>
  k(f(g(x)));
//  ^^^^^^^ deferring effect

const inc = x => x + 1;

const sqr = x => x * x;

const id = x => x;

const main = compk(
  sqr) (inc) (4);

// main is still unevaluated

main(id); // 25
```
[run code](https://repl.it/@scriptum/AppropriateBestObjectmodel)

CPS is a function encoding and allows us to control the rest of the computation and thus literally the rest of the program. This way we are able to compose arbitrarily complex compositions, which are technically nested function call trees. We will learn about continuation passing style in a subsequent chapter of this course.

### Description of computations

Function call trees are deferred function applications that are only evaluated when the initial value is provided. When we construct such computations we neither need to provide a value nor evaluate the computation in place. We defer it and still add types and new behavior layer by layer.

What is a proper notion of such a computation? It is not a normal computation anymore but a description of a computation. Since function call trees are just nested functions which are just functions which are ordinary values we can pass them around like data. We create and pass around descriptions of computations and it is up to the consumer of these structures to provide the necessary value to actually evaluated them.

### From nullary functions to implicit thunks

Using the inherent lazyness of functions for our own benefit is a very powerful technique and one of the major effects that the paradigm has on your code. However, we would like to have a more fine-grained control over the evaluation time of an arbitrarily expression. Javascript pursues an eager evaluation strategy, that is, we need to mimic lazyness somehow. The usual approach is to utilize nullary functions for that matter:

```javascript
const comp = f => g => x => () => f(g(x));
//                          ^^ nullary function
```
Nullary functions are also referred to as thunks in Javascript. They have a negative impact on the call side, because the consumer of such code needs to apply each thunk accordingly, even though there are no arguments. One way to abstract from nullary function application would be to rely on a special type (namely a functor) but at the price that lazyness would be restricted to values of this very type. Is there any alternative way to enable lazy evaluation along with ordinary expressions in general? There is indeed a way, provided you are willing to intercept property accesses and functions calls with the `Proxy` interface:

```javascript
// implicit thunks (simplified version)

const thunk = f =>
  new Proxy(f, new ThunkProxy());

const strict = thunk => {
  while (thunk && thunk[THUNK])
    thunk = thunk.valueOf();

  return thunk;
};

class ThunkProxy {
  constructor() {
    this.memo = undefined;
  }

  get(g, k) {
    if (this.memo === undefined) {
      this.memo = g();
      
      while (this.memo && this.memo[THUNK])
        this.memo = this.memo.valueOf();
    }

    if (k === THUNK)
      return true;

    else if (k === Symbol.toPrimitive)
      return this.memo[Symbol.toPrimitive];

    else if (k === "valueOf")
      return () => this.memo;

    else return this.memo[k];
  }
}

const THUNK = "thunk";

// auxiliary functions

const taggedLog = tag => x =>
  (console.log(tag, x), x);

const add = x => y =>
  thunk(() => taggedLog("add") (x + y));

const mul = x => y =>
  thunk(() => taggedLog("mul") (x * y));

// MAIN

const main = add(add(2) (3)) (mul(4) (5)); // WHNF
//               ^^^^^^^^^^   ^^^^^^^^^^ not immediately evaluated

// nothing logged yet!

// enforce evaluation
strict(main); // logs 5, 20, 25 and yields 25
```
[run code](https://repl.it/@scriptum/FarawayImmediateSyntax)

Please note that this is essentially the example from the beginning of this chapter but the presumably lazily evaluated version. Is this full-fledged lazyness? Let us verify whether we meet all requirements, namely normal order, WHNF and sharing, before we get too excited:

```javascript
// auxiliary functions

const taggedLog = tag => x =>
  (console.log(tag, x), x);

const add = x => y =>
  thunk(() => taggedLog("2 add 3 =") (x + y));

const mul = x => y =>
  thunk(() => taggedLog("5 mul 5 =") (x * y));

const foo = x => [
//Ë… here x is actually evaluated (A)
  x + x,
//    ^ here x is shared (C)
  x - x,
//^   ^ here x is shared (C)
  mul(x) (x)];
//^^^^^^^^^^ thunk (D)
  
// MAIN

const r = add(2) (3); // thunk

// add is still an unevaluated thunk

const main = foo(r); // logs "2 add 3 = 5" and yields [10, 0, thunk]
//           ^^^^^^ WHNF (B)

// mul is still an unevaluated thunk

// enforce evaluation
strict(main[2]); // logs "5 mul 5 = 25" and yields 25
```
[run code](https://repl.it/@scriptum/EasygoingUnhealthyAttribute)

`foo` evaluates its argument `add(2) (3)` only when needed (`A`), that is, when its result is used the first time within `foo`. `main` is in WHNF (`B`), because it contains an unevaluated thunk. `foo` evaluates `add(2) (3)` only once and shares the result (`C`). The result array of `foo` remains in WHNF, i.e. is evaluated just enough (`D`). We have achieved proper lazy evaluation in Javascript. This is huge! Let us discover some use cases for our lazy evaluation on demand strategy.

#### Guarded recursion

With our new tool at hand we can construct a lazy right associative fold, where the recursive step is wrapped in an implicit thunk. Such a lazy fold gives as stack safe recursion for free, provided the reducer function is lazy in its second argument:

```javascript
// ARRAY

const arrToList = xs =>
  tailRec((acc, i) =>
    i < 0
      ? Base(acc)
      : Step(Cons(xs[i]) (acc), i - 1))
        (Nil, xs.length - 1);

const arrFoldr_ = f => acc => xs => {
  const go = i =>
    i === xs.length
      ? acc
      : f(xs[i]) (thunk(() => go(i + 1)));

  return go(0);
};

const arrTake = n => xs => {
  const go = (acc, {head, tail}) =>
    head === undefined || acc.length === n
      ? acc
      : go(arrSnoc(head) (acc), tail);

  return go([], xs);
};

const arrSnoc = x => xs =>
  xs.concat([x]);

// trampoline

const tailRec = f => (...args) => {
    let step = f(...args);

    while (step.tag !== "Base")
      step = f(...step.args);

    return step.x;
};

const Base = x =>
  ({tag: "Base", x});

const Step = (...args) =>
  ({tag: "Step", args});

// auxiliary functions

const comp = f => g => x => f(g(x));
const add = x => y => x + y;
const neg = n => -n;

// MAIN

const xs = Array(1e5)
  .fill(0)
  .map((_, i) => i + 1);

const ys = arrToList(xs);

const main = listFoldr_(
  comp(Cons) (neg))
    (Nil)
      (ys);

main; // {head: -1, tail: thunk}
arrTake(5) (main); // [-1, -2, -3, -4, -5]

const main2 = arrFoldr_( // stack overflow
  comp(arrSnoc) (neg))
    ([])
      (xs);

  const main2 = listFoldr_( // stack overflow
    add)
      (0)
        (ys);
```
[run code](https://repl.it/@scriptum/ShadowyFlimsySmalltalk)

This property is referred to as guarded recursion, which is equivalent to tail call elimination modulo cons in eagerly evaluated languages. We will learn about the latter in a later chapter of this course. `main2` is not stack safe, because `add` is strict in both of its arguments. `main3` is not stack safe, because guarded recursion only works with purely functional data types like single linked `List`s, not with mutable `Array`s.

#### Infinite recursion

Lazy evaluation enables infinite recursions of otherwise non-terminating algorithms. `fix` has an infinite definition to express anonymous recursion:

```javascript
const fix = f => thunk(() => f(fix(f)));

const fact = fix(go => n =>
  n === 0
    ? 1
    : n * go(n - 1));

fact(5); // 120
```
[run code](https://repl.it/@scriptum/MurkyDetailedAutosketch)

The next algorithm infinitely applies a function to its previous result and accumulates the results in an array:

```javascript
// infinite recursion

const iterate = f => x =>
  Cons(x) (thunk(() => iterate(f) (f(x))));

// auxiliary function

const dbl = x => x * 2;

// MAIN

const main = iterate(dbl) (1);

arrTake(10) (main); // [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
```
[run code](https://repl.it/@scriptum/SilkyRosyGenres#index.js)

Given this mechanism we can defined a stream of infinite Fibonacci numbers:

```javascript
const fibs = [0, [1, thunk(() => {
  const next = ([x, [y, ys]]) =>
    [x + y, thunk(() => next([y, ys]))];

  return next(fibs);
})]];

fibs[1] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0]; // 55
```
[run code](https://repl.it/@scriptum/WiltedDarkseagreenCoolingfan)

#### Iterator-like data streams

Eagerly evaluated languages need iterators to lazily traverse a potentially infinite data structure. In a lazy evaluated setting we have incremental operations for free:

```javascript
// OPTION

const Option = union("Option");

const None = Option("None", {});

const Some = some => Option(Some, {some});

// ARRAY

const arrTakeWith = f => n => xs => {
  const go = (acc, {head, tail}) =>
    head === undefined || acc.length === n
      ? acc
      : go(arrSnoc(f(head)) (acc), tail);

  return go([], xs);
};

// auxiliary function

const fst = ([x, y]) => x;

// MAIN

const iterator = f => init => {
  const go = tx =>
    match(tx, {
      None: _ => Nil,
      Some: ({some: x}) => Cons(x) (thunk(() => go(f(x))))
    });
    
  return go(Some(init));
};

const main = iterator(
  ([x, i]) => i === 6
    ? None
    : Some([x * i, i + 1]))
        ([1, 1]);

arrTakeWith(fst) (10) (main); // [1, 1, 2, 6, 24, 120]
```
[run code](https://repl.it/@scriptum/TurboVeneratedLock)

This is just a naive implementation of an imperative-iterator-like infinite data structure, which is based on a lazy `List`. It behaves like an imperative iterator in terms of memory usage and the ability to encode infinite data streams. However, `iterator` is not equivalent to its imperative counterpart, because it is pure and thus can be cloned or composed. Besides it do not allow performing side effects. Lazyness makes it possible to operate incrementally on data streams without requiring an explicit data structure for this purpose.

#### Separating declaration from production

In general, the common theme here is that with lazily evaluated infinite data structures you can separate the declaration of a structure from the production of its contained values. The production is only triggered by the determination of which values are interesting to look at. This makes things more composable, because the choice of what is interesting to look at need not be known by the producer. You can certainly imagine that lazy evaluation exhibits many more meaningful use cases than demonstrated in this chapter. It is a vast field.

#### Enforcing evaluation

If we use functions with result expressions in WHNF, we sometimes need a means to enforce evaluation. This is the purpose of the `strict` combinator, which also handles arbitrarily nested thunks:

```javascript
const THUNK = "thunk";

const strict = thunk => {
  while (thunk[THUNK])
    thunk = thunk.valueOf();

  return thunk;
};
```
### Editor's note

If you enjoyed this chapter please ðŸŒŸ scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-005.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-007.md)
