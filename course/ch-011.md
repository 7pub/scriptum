## Immutability in Languages w/o Purely Functional Data Types

**[Editor's note: this chapter needs editing]**

Immutability in a language without purely functional data types entails more tedious and more verbose code. However, the advatanges of avoiding side effects outweight the drawbacks by far. Locating a nasty bug caused by a subtle side effect in a large code base is one of the most frustrating experiences of a programmer.

### Why mutability is harmful

Mutability is a side effect that give rise to the potential for a couple of error classes to your code. The larger your code base grows the harder it gets to keep side effects in check. For the time being we distinguish the following two classes, even though there are probably more:

* race conditions
* non-idempotence
* to be continued...

The first class is simple. Race conditions exist in any language. In single threaded Javascript they can occur through the event loop, which enables asynchronous computations. I use a short example to clarify the second class:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const empty = [];

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => fold(acc => x =>
  arrCons_(acc) (f(x)))
    ([]);

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9, 1, 4, 9]
```
[run code](https://repl.it/@scriptum/LowQuixoticThing)

The `main` operation is not idempotent as expected and thus yields `[1, 4, 9, 1, 4, 9]` instead of `[1, 4, 9]`. Mutations often render idempotent functions non-idempotent.

### The big trade-off with imperative data structures

So if we should not rely on mutations anymore, how are we supposed to handle Javascript's native data structures, which are mutable by design? You may treat them immutable, but it comes at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating brand new copies of the array for each iteration, while previous copies are just garbage collected. This is ridiculously inefficient, especially if you have to deal with larger amounts of data. I would recommend to use these composite types only for small data and resort to more suitable techniques otherwise. The following sections will show the most important approaches.

### Keeping side effects local

If you insist on relying on mutations in the context of imperative data structures, you can at least contain the risk by keeping side effects local:

```javascript
const push = x => xs =>
  (xs.push(x), xs);

const take = n => xs =>
  n === 0
    ? []
    : push(xs[n - 1]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The side effect only compromises `take`'s scope but not the global one. Local mutations are less harmful, because the space they could cause harm in is rather limited. However, bugs caused by local mutations are still often hard to spot, because they can be quite counterintuitive. It is a fine line. As a rule of thumb I would recommend not to rely upon local mutations except for really trivial cases.

### Utilizing eta abstraction

Another technique to prevent side effects from leaking into the global scope are eta abstractions, that is, adding redundant function layers:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/@scriptum/RaggedAccomplishedQueries)

In the example above the redundant lambda abstraction forces `map` to create a fresh array for each invocation.

### Indirect data association

If you want to associate data components that are not available upfront but are received in individual batches in the course of the program, you have three options in a language without immutable data structures:

* destructively update a mutable composite data structure
* safely update a mutable composite data structure by copying it first
* establish an indirect association by sharing structure

I want to demonstrate the last approach using a rather contrived example. The underlying idea is that each involved data component uses the same structure so that groups of data can be arranged just by considering this structure:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
If we look at these three data structures it is possible to deduce from the original relations between their data components: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. The downside of this approach is that it encodes data relations rather implicitly and leaves a lot of room for interpretation.

### Persistent data structures and structural sharing

At a certain point we cannot get around introducing real immutable data types. Such types have not only a persistent structure but share as much of it as possible across instances. They are referred to as persistent data structures with structural sharing. Instead of relying on subtle and counterintuitive side effects we can now program against stringent APIs which exhibit predictable and reliable behavior. These custom types are not as seamlessly incoporated into the language as native ones, of course and their handling is more verbose and more tedious. Having them in our toolbox is still a huge leap forward.

#### Inherent persistence

The functional single linked `List` type is inherently persistent. We can trivially mimic it with an two element array used as a pair tuple:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);
  
const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail => List(Cons, {head, tail});

const cons_ = tail => head =>
  List(Cons, {head, tail});

// Monoid

const listAppend = xs => ys =>
  listFoldr(x => acc =>
    Cons(x) (acc)) (ys) (xs);

// Foldable

const listFoldr = f => acc =>
  rec(xs =>
    match(xs, {
      Nil: _ => Base(acc),
      Cons: ({head, tail}) => Call(f(head), Step(tail))
    }));

// trampoline

const rec = f => (...args) => {
  let step = f(...args);
  const stack = [];

  while (step.tag !== "Base") {
    stack.push(step.f);
    step = f(...step.step.args);
  }

  let r = step.x;

  for (let i = stack.length - 1; i >= 0; i--) {
    r = stack[i] (r);
    
    if (r && r.tag === "Base") {
      r = r.x;
      break;
    }
  }

  return r;
};

const Base = x =>
  ({tag: "Base", x});

const Call = (f, step) =>
  ({tag: "Call", f, step});

const Step = (...args) =>
  ({tag: "Step", args});

// MAIN

const xs = Cons(1) (Cons(2) (Cons(3) (Nil))),
  ys = Cons(4) (Cons(5) (Cons(6) (Nil)));

listAppend(xs) (ys); // Cons(1) (Cons(2) (Cons(3) (Cons(4) (Cons(5) (Cons(6) (Nil))))))
```
[run code](https://repl.it/@scriptum/PeriodicMoccasinUpgrade)

The algorithm above right associatively folds `xs` and as soon as it reaches `Nil` it appends the entire `ys` list structure in-place, i.e. it does not need to traverse the second list. This is a form of structural sharing and `List` provides it for free.

#### Persistence through functional optics

Plain old Javascript objects are a mutable data type. However, if we use them as nested trees rather than as maps we can regain persistent behavior. The trick is to use them along with functional lenses and other optics, which automatically take care of copying and structural sharing. Lenses are the functional pattern for getters and setters. They are part of a family of optical tools and a rather advanced topic. We will only look more closely into functional optics in subsequent chapters of this course.

#### Persistence through hashed array mapped tries

Persistent data structures maintain persistency by an efficient copy mechanism referred to as structural sharing. If you alter such a data structure only the portion that is affected by the alteration is actually copied, whereas the rest is shared between the current and the previous state. This also means that all previous states are preserved. There are no destructive updates. Persistent data types are regularly based on trees. An update of a leave of this tree requires the path to this leave to be copied whereas the rest of the tree can be shared. No matter how ramified the tree is, the efficiency of our copy mechanism is only affected by the depth of the path.

scriptum uses a special variant of a tree to model persistent data structures, namely a trie or more specifically, a hashed array mapped trie (Hamt). `Hamt` exhibits a promising performance, can handle all kind of types as keys and supplies a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value pairs are the same except for the selected key with the modified value.

##### An immutable array

We can develop a better feeling for dealing with persistent data structures by having a quick glance at a specific implementation. Here is an excerpt from the `Iarray` API:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
//                ^^^^^
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);
//      ^^^^

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/@scriptum/MessyGlumHexadecimal)

***

`iarrCons`/`iarrSnoc` are the immutable functional counterparts of `unshift`/`push`, as they are used in the imperative paradigm. It should be clearer now how the `props` argument from the API is meant to be used. It declares data structure specific properties. `hamtSet` expects even two property arguments, because setting actually consists of two operations: One to add a new key/value pair and another to modify an existing one.

You have probably already seen a crucial downside of `Hamt` and persistent data structures in general: They are not native and therefore require a lot of back and forth transformation. `Hamt` is a tradeoff between performance gain through structural sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb we can state that the benefits outweigh their drawbacks when dealing with both large amounts of data and a lot of modifications.

By the way, did you notice that I had to deal with the _non-idempotence_ error from the first example of this chapter again? I had to put `iarrToArr` in a redundant lambda abstraction to keep the operation idempotent. This is necessary because I treat arrays as a mutable data type and consequently have to take care of side effects. See what happens when I [remove the redundant lambda abstraction](https://repl.it/@scriptum/QuaintStableTests).

Now we are prepared to reimplement the `Array`-based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/@scriptum/ComplicatedInformalStatistics)

### Editor's note

If you enjoyed this chapter please 🌟 scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-010.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-012.md)
