## Immutability in Languages w/o Purely Functional Data Types

Immutability in a language without purely functional data types entails more tedious and more verbose code. However, the advantages of avoiding side effects outweigh the drawbacks by far. Locating a nasty bug caused by a subtle side effect in a large code base is one of the most frustrating experiences of a programmer.

### Why mutability is harmful

Just like I/O operations mutations are a side effect that introduces time and thus tremendous complexity into your program. Suddenly it matters if an otherwise associative expression is evaluated before or after another. This has the following consequences:

* time gives rise to race conditions (through asynchronous computations in Javascript)
* time renders more functions non-idempotent (`f(x) ≠ f(f(x))`)
* time renders more functions non-associative (`f(x) (f(y) (z)) ≠ f(f(x) (y)) (z))`)
* time renders more functions non-commutative (`f(x) (y) ≠ f(y) (x)`)

Partially losing these properties has far-reaching consequences on your functional programming experience. Side effects hamper

* parallelization
* local reasoning
* equational reasoning

In other words you can program with side effects but it is not functional programming anymore. Here are two examples how mutations are at the expense of idempotency and assocaitivity. Please note that I use a more relaxed form of idempotency, as it often occurs in programming:

```javascript
// IDEMPOTENCY

const xs = [1, 2]
  ys = [3, 4];

// impure

const append = xs => ys =>
  (xs.push.apply(xs, ys), xs);

append(xs) (ys);
append(xs) (ys); // [1, 2, 3, 4, 3, 4]

// pure

const append2 = xs => ys =>
  xs.concat(ys);

append(xs) (ys);
append(xs) (ys); // [1, 2, 3, 4]

// ASSOCIATIVITY

// impure

let x = 1;
(10 + --x) * x; // 0
10 + (--x * x); // 10

// pure

const y = 1;
(10 + (y - 1)) * y; // 10
10 + ((y - 1) * y); // 10
```
### The big trade-off with imperative data structures

So if we should not rely on mutations anymore how are we supposed to handle Javascript's native data structures, which are mutable by design? You may treat them immutable, but it comes at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating brand new copies of the array for each iteration, while previous copies are just garbage collected. This is ridiculously inefficient, especially if you have to deal with larger amounts of data. I would recommend using these composite types only for small data and resort to more suitable techniques otherwise. The following sections will show the most relevant approaches.

### Keeping side effects local

If you insist on relying on mutations in the context of imperative data structures, you can at least contain the risk by keeping side effects local:

```javascript
const push = x => xs =>
  (xs.push(x), xs);

const take = n => xs =>
  n === 0
    ? []
    : push(xs[n - 1]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The side effect only leaks into `take`'s scope but not into the global one. Local mutations are less harmful, because the space they could cause harm in is rather limited. However, bugs caused by local mutations are still often hard to spot, because they can be quite subtle and counterintuitive. It is a fine line. As a rule of thumb I would recommend not to rely upon local mutations except for really trivial cases.

### Utilizing eta abstraction

Another technique to prevent side effects from leaking into the global scope are eta abstractions, that is, adding redundant function layers:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/@scriptum/RaggedAccomplishedQueries)

In the example above the redundant lambda abstraction forces `map` to create a fresh array for each invocation.

### Indirect data association

If you want to associate data components that are not available upfront but are received in individual batches in the course of the program, you have three options in a language without immutable data structures:

* destructively update a mutable composite data structure
* safely update a mutable composite data structure by copying it first
* establish an indirect association by sharing structure

I want to demonstrate the last approach using a rather contrived example. The underlying idea is that each involved data component uses the same structure so that groups of data can be recovered just by considering this structure:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
If we look at these three data structures it is possible to deduce from the original relations between their data components: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. The downside of this approach is that it encodes data relations rather implicitly and leaves a lot of room for interpretation.

### Persistent data structures and structural sharing

At a certain point we cannot get around introducing real immutable data types. Such types have not only a persistent structure but share as much of it as possible across instances. They are referred to as persistent data structures with structural sharing. Instead of relying on subtle and counterintuitive side effects we can now program against stringent APIs which exhibit predictable and reliable behavior. These custom types are not as seamlessly incorporated into the language as native ones, of course and their handling is more verbose and more tedious. Having them in our toolbox is still a huge leap forward.

#### Inherent persistence

The functional single linked `List` type is inherently persistent. We can trivially mimic it with a two element array used as a pair tuple:

```javascript
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);
  
const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail => List(Cons, {head, tail});

const cons_ = tail => head =>
  List(Cons, {head, tail});

// Monoid

const listAppend = xs => ys =>
  listFoldr(x => acc =>
    Cons(x) (acc)) (ys) (xs);

// Foldable

const listFoldr = f => acc =>
  rec(xs =>
    match(xs, {
      Nil: _ => Base(acc),
      Cons: ({head, tail}) => Call(f(head), Step(tail))
    }));

// trampoline

const rec = f => (...args) => {
  let step = f(...args);
  const stack = [];

  while (step.tag !== "Base") {
    stack.push(step.f);
    step = f(...step.step.args);
  }

  let r = step.x;

  for (let i = stack.length - 1; i >= 0; i--) {
    r = stack[i] (r);
    
    if (r && r.tag === "Base") {
      r = r.x;
      break;
    }
  }

  return r;
};

const Base = x =>
  ({tag: "Base", x});

const Call = (f, step) =>
  ({tag: "Call", f, step});

const Step = (...args) =>
  ({tag: "Step", args});

// MAIN

const xs = Cons(1) (Cons(2) (Cons(3) (Nil))),
  ys = Cons(4) (Cons(5) (Cons(6) (Nil)));

listAppend(xs) (ys); // Cons(1) (Cons(2) (Cons(3) (Cons(4) (Cons(5) (Cons(6) (Nil))))))
```
[run code](https://repl.it/@scriptum/PeriodicMoccasinUpgrade)

The algorithm above right associatively folds `xs` and as soon as it reaches `Nil` it appends the entire `ys` list structure in-place, i.e. it does not need to traverse the second list. This is a form of structural sharing and `List` provides it for free.

#### Persistence through functional optics

Plain old Javascript objects are a mutable data type. However, if we use them as nested trees rather than as maps we can regain persistent behavior. The trick is to use them along with functional lenses and other optics, which automatically take care of copying and structural sharing. Lenses are the functional pattern for imperative getters and setters. They are part of a family of optical tools and a rather advanced topic. We will only look more closely into functional optics in subsequent chapters of this course.

#### Persistence through hashed array mapped tries

Persistent data structures maintain persistency by an efficient copy mechanism referred to as structural sharing. If you alter such a data structure only the portion that is affected by the alteration is actually copied, whereas the rest is shared between the current and the previous state. Consequently, all previous states are preserved, because there are no destructive updates anymore. Persistent data types are regularly based on trees. An update of a leave of this tree requires the path to this leave to be copied whereas the rest of the tree can be shared. No matter how ramified the tree is, the efficiency of our copy mechanism is only depends on the depth of the path.

scriptum uses a special variant of a tree to model persistent data structures, namely a trie or more specifically, a hashed array mapped trie (Hamt). `Hamt` exhibits a promising performance, can handle all kinds of types as keys and supplies a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value-pairs are the same except for the selected key with the modified value.

##### An immutable array

We can develop a better feeling for persistent data structures by having a quick glance at a specific implementation. Here is the necessary excerpt from the `Iarray` API to do so:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/@scriptum/MessyGlumHexadecimal)

`iarrCons`/`iarrSnoc` are the immutable counterparts of the destructive `unshift`/`push` operations. You have probably seen a crucial downside of `Hamt` already: Since they are not native they require a lot of back and forth transformation. `Hamt` is a trade-off between performance gains through structural sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb it applies that the benefits outweigh the drawbacks as soon as we deal with either large amounts of data or a lot of modifications or both, of course.

Now we are ready to reimplement the array based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/@scriptum/ComplicatedInformalStatistics)

### Editor's note

If you enjoyed this chapter please 🌟 scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-010.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-012.md)
