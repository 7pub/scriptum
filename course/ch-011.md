## Immutability in Languages w/o Purely Functional Data Types

**[Editor's note: this chapter needs editing]**

Immutability in a language without purely functional data types is a tough nut. It took me quite some time to explore the advantages and disadvantages and draw a few general conclusions. Here is my shot.

### Why mutability is harmful

Mutability is a side effect that introduces different kinds of potential errors to your code. The larger your code base grows the harder it gets to keep them in check. As far as I know we can distinguish two distinct error classes:

* race conditions
* non-idempotence

The first point is simple. Race conditions exist in any language. In single threaded Javascript they can occur through the event loop, which allows asynchronous computations. I use a short example to clarify the second point:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const empty = [];

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => fold(acc => x =>
  arrCons_(acc) (f(x)))
    ([]);

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9, 1, 4, 9]
```
[run code](https://repl.it/@scriptum/LowQuixoticThing)

The `main` operation is not idempotent as expected and thus yields `[1, 4, 9, 1, 4, 9]` instead of `[1, 4, 9]`. Mutations often render idempotent functions to non-idempotent ones.

### Why immutability is useful

Immutability does not magically make complexity disappear. It just replaces the complexity caused by side effects with an extra level of indirection. However, working with immutable data types is much more comprehensible for most developers than dealing with subtle and hardly predictable side effects, because the former are based on clear rules and principles and are explicit. So in the end this tradeoff is worth the hassle, as you can hopefully see in this chapter.

### Using data types according to their design

Javascript native composite data types are mutable by design. You may treat them as immutable but it comes at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating brand new copies of the array for each iteration, while previous copies are just garbage collected. This is ridiculously inefficient, especially if you have to deal with larger amounts of data. I would recommend to use these composite types only for small data and resort to purely functional single linked lists or immutable arrays based on hashed array mapped tries otherwise. Both data structures are covered in later sections of this chapter.

### Keeping mutations local

We can render the example above more efficient by relying on local mutations:

```javascript
const push = x => xs =>
  (xs.push(x), xs);

const take = n => xs =>
  n === 0
    ? []
    : push(xs[n - 1]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The side effect only affects `take`'s scope but not the global one. Such mutations are less harmful, because unintneded side effects and race conditions are now limited in space. However, bugs caused by local mutations are still often hard to find. It is a thin line! As a rule of thumb I would recommend not to rely upon local mutations except for really trivial cases.

### Copying as a last resort

Sometimes we cannot keep side effects from leaking into the parent scope. In these cases we have to copy the data structure once right before we start the computation. For the example from the beginning of this chapter copying just means to put the array literal in a redundant lambda abstraction, so that each invocation creates a new array instance:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/@scriptum/RaggedAccomplishedQueries)

### Reducing the need for mutability

A frequent scenario where mutability matters is gradual data acquisition. Imagine you successively query external data, process it and query further external data depending on the result of the previous processing step. If there are relations between both chunks of data you usually maintain them by arranging the data within a compound data type in a certain way. Since you do not have all data upfront, this data structure is gradually growing. On first sight there seem to be only two alternatives: Either mutate the data structure or copy it before each update.

However, a viable third alternative is to create a separate structure for each chunk of data and maintain relations between data chunks by sticking to a certain shape:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
Given these three data structures it is quite easy to retrieve the relation between their data components: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. While this approach works for scenarios with only few updates it quickly gets convoluted as soon as the number of updates grows.

### Persistent data structures and structural sharing

#### Inherent persistence

The functional single linked `List` type let you benefit from structural sharing quite naturally:

```
// union constructor

const union = type => (tag, o) =>
  (o[type] = type, o.tag = tag.name || tag, o);
  
const match = (tx, o) =>
  o[tx.tag] (tx);

// LIST

const List = union("List");

const Nil = List("Nil", {});

const Cons = head => tail => List(Cons, {head, tail});

const cons_ = tail => head =>
  List(Cons, {head, tail});

// Monoid

const listAppend = xs => ys =>
  listFoldr(x => acc =>
    Cons(x) (acc)) (ys) (xs);

// Foldable

const listFoldr = f => acc =>
  rec(xs =>
    match(xs, {
      Nil: _ => Base(acc),
      Cons: ({head, tail}) => Call(f(head), Step(tail))
    }));

// trampoline

const rec = f => (...args) => {
  let step = f(...args);
  const stack = [];

  while (step.tag !== "Base") {
    stack.push(step.f);
    step = f(...step.step.args);
  }

  let r = step.x;

  for (let i = stack.length - 1; i >= 0; i--) {
    r = stack[i] (r);
    
    if (r && r.tag === "Base") {
      r = r.x;
      break;
    }
  }

  return r;
};

const Base = x =>
  ({tag: "Base", x});

const Call = (f, step) =>
  ({tag: "Call", f, step});

const Step = (...args) =>
  ({tag: "Step", args});

// MAIN

const xs = Cons(1) (Cons(2) (Cons(3) (Nil))),
  ys = Cons(4) (Cons(5) (Cons(6) (Nil)));

listAppend(xs) (ys); // Cons(1) (Cons(2) (Cons(3) (Cons(4) (Cons(5) (Cons(6) (Nil))))))
```
[run code](https://repl.it/@scriptum/PeriodicMoccasinUpgrade)

The algorithm above right associatively folds `xs` and as soon as it reaches `Nil` it appends the entire `ys` list structure in-place, i.e. it does not need to traverse the second list. This is a form of structural sharing and `List` provides it for free.

#### Persistence through functional optics

Technically plain old Javascript objects are unordered maps based on hash tables. However, you should not use them as dictionaries but rather as records, which you can nest to construct arbitrarily tree structures. Such nested objects exhibit an interesting trait as soon as you modify its fields with functional lenses. They behave like persistent data structures. Lenses are the functional pattern for getters and setters. They are an advanced topic that depends on a couple of other functional techniques, though. We will look more closely into the topic in a subsequent chapter of this course.

#### Persistence through hashed array mapped tries

Persistent data structures gain immutability by maintaining all previous states. When you change such a structure only the portion that is actually altered gets copied, whereas the rest is shared between instances. Since persistent data structures are organized as trees that means only the involved node including its nodes along the root path are copied. This technique is referred to as structural sharing and enables efficient copying.

`Hamt`, the persistent data structure used in this course, is based on a hashed array mapped trie (HAMT). Besides `String`s it allows all sorts of types as keys, including `Object`s. It has a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value pairs are the same except for the selected key with the modified value.

##### An immutable array

We can gain a better feeling how to handle persistent data structures by having a quick glance at a specific implementation. Here is an excerpt from the `Iarray` API:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
//                ^^^^^
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);
//      ^^^^

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/@scriptum/MessyGlumHexadecimal)

`iarrCons`/`iarrSnoc` are the immutable functional counterparts of `unshift`/`push`, as they are used in the imperative paradigm. It should be clearer now how the `props` argument from the API is meant to be used. It declares data structure specific properties. `hamtSet` expects even two property arguments, because setting actually consists of two operations: One to add a new key/value pair and another to modify an existing one.

You have probably already seen a crucial downside of `Hamt` and persistent data structures in general: They are not native and therefore require a lot of back and forth transformation. `Hamt` is a tradeoff between performance gain through structural sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb we can state that the benefits outweigh their drawbacks when dealing with both large amounts of data and a lot of modifications.

By the way, did you notice that I had to deal with the _non-idempotence_ error from the first example of this chapter again? I had to put `iarrToArr` in a redundant lambda abstraction to keep the operation idempotent. This is necessary because I treat arrays as a mutable data type and consequently have to take care of side effects. See what happens when I [remove the redundant lambda abstraction](https://repl.it/@scriptum/QuaintStableTests).

Now we are prepared to reimplement the `Array`-based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/@scriptum/ComplicatedInformalStatistics)

### Editor's note

If you enjoyed this chapter please 🌟 scriptum here on Github or share it on your preferred social media platform. If you found a mistake or inaccuracy or want to propose an improvement please file an issue/feature. Thank you.

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/course/ch-010.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc) | [next chapter &gt;](https://github.com/kongware/scriptum/blob/master/course/ch-012.md)
