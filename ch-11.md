## Immutability in Languages w/o Purely Functional Data Types

Immutability in a language without purely functional data types is a tough nut. It took me quite some time to explore the advantages and disadvantages and draw a few general conclusions. Here is my shot.

### Why mutability is harmful

Mutability is a side effect that introduces different kinds of potential errors to your code. The larger your codebase grows the harder it gets to keep them in check. As far as I know we can distinguish two distinct error classes:

* race conditions
* non-idempotence

The first point is simple. Race conditions exist in any language. In single threaded Javascript they can occur through the event loop, which allows asynchronous computations. I use a short example to clarify the second point:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const empty = [];

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => fold(acc => x =>
  arrCons_(acc) (f(x)))
    ([]);

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9, 1, 4, 9]
```
[run code](https://repl.it/repls/LowQuixoticThing)

The `main` operation is not idempotend as expected and thus yields `[1, 4, 9, 1, 4, 9]` instead of `[1, 4, 9]`. Mutations often render idempotent functions to non-idempotent ones.

### Why immutability is useful

Immutability does not magically make complexity disappear. It just replaces the complexity caused by side effects with an extra level of indirection. However, working with immutable data types is much more comprehensible for most developers than dealing with subtle and hardly predictable side effects, because the former are based on clear rules and principles and are explicit. So in the end this trade-off is worth the hassle, as you can hopefully see in this chapter.

### Use data types according to their design

Javascript is based on native data types that are inherently mutable. You may treat them as immutable but it is at the expense of their efficiency:

```javascript
const take = n => ([x, ...xs]) =>
//                     ^^^^^
  n === 0
    ? []
    : [x].concat(take(n - 1) (xs));
//        ^^^^^^

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // incredible inefficient
```
Both underlined lines of code are responsible for creating a brand new copy of the array for each iteration, while the previous one is just thrown away. This is ridiculously inefficient. Personally I think the rest syntax and `concat` are among the most harmful operations in Javascript, since they entice developers to misuse arrays.

It is crucial to understand that immutability in a multi-paradigm language is not a silver bullet. You must use data types in a way that they were designed to be used. Do not attampt to convert mutable data types into immutable ones.

### Keep mutations local

We can render the above example more efficient by relying on local mutability:

```javascript
const push = x => xs => (xs.push(x), xs);

const take = n => xs =>
  n < 0
    ? []
    : push(xs[n]) (take(n - 1) (xs));

const xs = Array(1e5).fill(1).map((x, i) => x + i);

take(200) (xs); // quite efficient
```
The mutation only takes place inside `take` and is not visible in the parent scope. Such mutations are managable, because race conditions and other potential errors are now delimited to the function scope.

### Copy as a last resort

Sometimes we cannot keep side effects from leaking into the parent scope. In these cases we have to copy the data structure once right before we start the computation. For the example from the beginning of this chapter copying just means to put the array literal in an redundant lambda abstraction, so that each invocation creates a new array instance:

```javascript
const arrCons_ = xs => x =>
  (xs.unshift(x), xs);

const fold = f => acc => ([x, ...xs]) =>
  x === undefined
    ? acc
    : f(fold(f) (acc) (xs)) (x);

const map = f => xs => fold(acc => x =>
//               ^^^^^
  arrCons_(acc) (f(x)))
    ([])
      (xs);
//    ^^^^

const sqr = x => x * x;

const xs = [1, 2, 3];

const main = map(sqr);

main(xs);
main(xs); // [1, 4, 9]
```
[run code](https://repl.it/repls/RaggedAccomplishedQueries)

### Reduce the need for immutability

A frequent scenario where immutability matters is gradual data acquisition. Imagine you successively query external data, process it and query further external data depending on the result of the previous processing step. If there are relations between both chunks of data you usually maintain them by arranging the data within a compound data type in a certain way. Since you do not have all data upfront, this data structure is gradually growing. On first sight there seem to be only two alternatives: Either mutate the data structure or copy it before each update.

However, a viable third alternative is to create a separate structure for each chunk of data and maintain relations between data chunks by sticking to a certain shape:

```javascript
const foo = {
  keyA: {
    keyB: [1, 2, 3],
    /*...*/
  },
  /*...*/
};

const bar = {
  keyA: {
    keyB: ["a", "b", "c"],
    /*...*/
  },
  /*...*/
};

const baz = {
  keyA: {
    keyB: [true, false, false],
    /*...*/
  },
  /*...*/
};
```
Given these three data structures it is quite easy to retrieve the relation between their data components: `[1, "a", true]`, `[2, "b", false]` and `[3, "c", false]`. While this approach works for settings with few updates it quickly gets convoluted as soon as the number of updates grow significantly.

### Immutable objects through functional lenses

Technically plain old Javascript objects are unordered maps based on hash tables. However, you should not use them as dictionaries but rather as plain records, which you can nest to form arbitrarily tree structures.

Nested objects have an interesting trait as soon as you access them with functional lenses to set, delete or update nodes. They act like persistent data structures. Hence there is no need for immutable objects. Lenses are the functional idiom of combined getters and setters. Since they are an advanced topic that depends on a couple of other functional techniques they will only be covered in a subsequent chapter of this course.

### Persistent data structures and structural sharing

Persistent data structures gain immutability by maintaining all previous states. When you change such a structure only the portion that is actually altered gets copied, whereas the rest is shared between instances. Since persistent data structures are organized as trees that means only the involved node including its nodes along the root pathe are copied. This technique is referred to as structural sharing and enables efficient copying.

`Hamt`, the persistent data structure used in this course, is based on a hashed array mapped trie (HAMT). Besides `String`s it allows all sorts of types as keys, including `Object`s. It has a pretty straightforward API:

```javascript
Hamt(props)
// takes an object with arbitrary properties
// returns fresh empty Hamt with these extra properties

hamtGet(hamt, k)
// takes a hamt and a key of arbitrary type
// returns the corresponding value

hamtHas(hamt, k)
// takes a hamt and a key
// returns true if the key exists and false otherwise

hamtSet(hamt, props1, props2, k, v)
// takes a hamt, two objects, a key and a value
// returns a new hamt with the value set under the given key

hamtDel(hamt, props, k)
// takes a hamt, an object and a key
// returns a new hamt with the key removed

hamtUpd(hamt, props, k, f)
// takes a hamt, an object, a key and a pure function
// returns a new hamt with the updated value under the given key
```
The principle to modify such a persistent data structure is pretty simple: A function takes at least a `Hamt` instance, a key and an object with some properties and returns a new `Hamt`, where all key/value pairs are the same except for the selected key with the modified value.

#### An immutable array

We can gain a better feeling how to handle persistent data structures by having a quick glance at a specific implementation. Here is an excerpt from the `Iarray` API:

```javascript
const Iarray = Hamt(
  {length: 0, offset: 0});

const iarrCons = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset - 1},
    xs.offset - 1,
    x);

const iarrSnoc = x => xs =>
  hamtSet(
    xs,
    {},
    {length: xs.length + 1, offset: xs.offset},
    xs.length,
    x);

const iarrFold = f => acc => xs => {
  for (let i = 0; i < xs.length; i++)
    acc = f(acc) (hamtGet(xs, i + xs.offset), i);

  return acc;
};

const iarrFromArr = arrFold(
  acc => (x, i) =>
    hamtSet(acc, {}, {length: acc.length + 1, offset: 0}, i, x))
      (Iarray);

const iarrToArr = xs =>
//                ^^^^^
  iarrFold(
    acc => (x, i) => arrSnoc(x) (acc))
      ([])
        (xs);
//      ^^^^

const xs = iarrFromArr([1, 2, 3, 4, 5]);

iarrToArr(iarrCons(0) (xs)); // [0, 1, 2, 3, 4, 5]
iarrToArr(iarrSnoc(6) (xs)); // [1, 2, 3, 4, 5, 6]
```
[run code](https://repl.it/repls/MessyGlumHexadecimal)

`iarrCons`/`iarrSnoc` are the immutable functional counterparts of `unshift`/`push`, as they are used in the imperative paradigm. It should be clearer now how the `props` argument from the API is meant to be used. It declares data structure specific properties. `hamtSet` expects even two prperty arguemtns, because setting actually consists of two operations: One to add a new key/value pair and another to modify an existing one.

You have probably already seen a crucial downside of `Hamt` and persistent data structures in general: They are not native and therefore require a lot of back and forth transformation. `Hamt` is a tradeoff between performance gain through strucutral sharing on the one hand and performance loss through transformations on the other hand. As a rule of thumb we can state that the benefits outweigh their drawbacks when dealing with both large amounts of data and a lot of modifications.

By the way, did you notice that I had to deal with the _non-idempotence_ error from the first example of this chapter again? I had to put `iarrToArr` in a redundant lambda abstraction to keep the operation idempotent. This is necessary because I treat arrays as a mutable data type and consequently have to take care of side effects. See what happens when I [remove the redundant lambda abstraction](https://repl.it/repls/QuaintStableTests).

Now we are prepared to reimplement the `Array`-based and thus inefficient `take` function from the beginning of this chapter. We implement it with the very same algorithm but with `Iarray` as its underlying data structure:

```javascript
const arrTake = n => ([x, ...xs]) =>
  n === 0
    ? []
    : [x].concat(arrTake(n - 1) (xs));

const iarrTake = n => xs => {
  const go = ([y, ys], m) =>
    m === 0
      ? Iarray
      : iarrCons(y) (go(iarrUncons(ys), m - 1));

  return go(iarrUncons(xs), n);
};

const xs = Array(1e5).fill(1).map((x, i) => x + i),
  ys = iarrFromArr(xs);

arrTake(200) (xs);
iarrTake(200) (ys); // way more efficient
```
[run code](https://repl.it/repls/ComplicatedInformalStatistics)

[&lt; prev chapter](https://github.com/kongware/scriptum/blob/master/ch-10.md) | [TOC](https://github.com/kongware/scriptum#functional-programming-course-toc)
